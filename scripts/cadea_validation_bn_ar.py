{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-09T21:51:57.757280Z\",\"iopub.execute_input\":\"2026-02-09T21:51:57.757592Z\",\"iopub.status.idle\":\"2026-02-09T21:51:58.031692Z\",\"shell.execute_reply.started\":\"2026-02-09T21:51:57.757556Z\",\"shell.execute_reply\":\"2026-02-09T21:51:58.031100Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-09T21:51:58.032832Z\",\"iopub.execute_input\":\"2026-02-09T21:51:58.033193Z\",\"iopub.status.idle\":\"2026-02-09T21:52:16.487029Z\",\"shell.execute_reply.started\":\"2026-02-09T21:51:58.033170Z\",\"shell.execute_reply\":\"2026-02-09T21:52:16.486337Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n!pip uninstall -y transformers\n!pip install --no-cache-dir transformers==4.46.3 datasets accelerate sentencepiece protobuf\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-09T21:52:16.488216Z\",\"iopub.execute_input\":\"2026-02-09T21:52:16.488430Z\",\"iopub.status.idle\":\"2026-02-09T21:52:16.492832Z\",\"shell.execute_reply.started\":\"2026-02-09T21:52:16.488407Z\",\"shell.execute_reply\":\"2026-02-09T21:52:16.492286Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport shutil\nimport os\ncache_dir = os.path.expanduser(\"~/.cache/huggingface/hub\")\nif os.path.exists(cache_dir):\n    shutil.rmtree(cache_dir)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-09T21:52:16.494423Z\",\"iopub.execute_input\":\"2026-02-09T21:52:16.494820Z\",\"iopub.status.idle\":\"2026-02-09T21:52:27.803713Z\",\"shell.execute_reply.started\":\"2026-02-09T21:52:16.494783Z\",\"shell.execute_reply\":\"2026-02-09T21:52:27.802988Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# CELL 1: Environment Setup\n# ============================================================================\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, get_linear_schedule_with_warmup\nfrom datasets import load_dataset\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-09T21:52:27.804472Z\",\"iopub.execute_input\":\"2026-02-09T21:52:27.804957Z\",\"iopub.status.idle\":\"2026-02-09T21:52:27.808487Z\",\"shell.execute_reply.started\":\"2026-02-09T21:52:27.804934Z\",\"shell.execute_reply\":\"2026-02-09T21:52:27.807943Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport os\n\nos.environ[\"HF_TOKEN\"] = \"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\"\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-09T21:52:27.809424Z\",\"iopub.execute_input\":\"2026-02-09T21:52:27.809689Z\",\"iopub.status.idle\":\"2026-02-09T21:52:27.830203Z\",\"shell.execute_reply.started\":\"2026-02-09T21:52:27.809661Z\",\"shell.execute_reply\":\"2026-02-09T21:52:27.829708Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# CELL 2: Configuration\n# ============================================================================\nclass Config:\n    model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n    \n    # English dataset\n    en_dataset = \"tatsu-lab/alpaca\"\n    en_samples = 100\n    \n    # Bengali dataset - Native instruction data (not translation)\n    bn_dataset = \"md-nishat-008/Bangla-Instruct\"\n    bn_samples = 5000\n    \n    # Arabic dataset - Human-reviewed culturally relevant instructions\n    ar_dataset = \"arbml/CIDAR\"\n    ar_samples = 5000  # Note: Only 10K total available\n    \n    batch_size = 2\n    learning_rate = 5e-6\n    gradient_accumulation = 2\n    \n    layers_to_track = [0, 3, 6, 9, 12, 15]\n    log_interval = 50\n    total_steps = 2000\n    \n    max_length = 512\n    use_fp16 = False\n    use_bf16 = True \n    gradient_checkpointing = True\n\nconfig = Config()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-09T21:52:27.831059Z\",\"iopub.execute_input\":\"2026-02-09T21:52:27.831582Z\",\"iopub.status.idle\":\"2026-02-09T21:53:06.106351Z\",\"shell.execute_reply.started\":\"2026-02-09T21:52:27.831554Z\",\"shell.execute_reply\":\"2026-02-09T21:53:06.105780Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# CELL 3: Load Model with Memory Optimization\n# ============================================================================\n\nprint(\"Loading model...\")\n\ntokenizer = AutoTokenizer.from_pretrained(\n    config.model_name,\n    trust_remote_code=True,\n    token=os.getenv(\"HF_TOKEN\")\n)\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\n\n# Load with attn_implementation specified - this bypasses rope_scaling validation\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.model_name,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    low_cpu_mem_usage=True,\n    token=os.getenv(\"HF_TOKEN\"),\n    attn_implementation=\"sdpa\"  # This is the fix\n)\n\nif config.gradient_checkpointing:\n    model.gradient_checkpointing_enable()\n\nmodel.train()\nprint(f\"Model loaded. Total parameters: {sum(p.numel() for p in model.parameters()) / 1e9:.2f}B\")\nprint(f\"Memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-09T21:53:06.107349Z\",\"iopub.execute_input\":\"2026-02-09T21:53:06.107846Z\",\"iopub.status.idle\":\"2026-02-09T21:53:48.661891Z\",\"shell.execute_reply.started\":\"2026-02-09T21:53:06.107824Z\",\"shell.execute_reply\":\"2026-02-09T21:53:48.661292Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# CELL 4: Dataset Preparation with Validation\n# ============================================================================\n\ndef prepare_dataset(dataset_name, num_samples=500, max_length=512):\n    \"\"\"Load and prepare instruction dataset with robust error handling\"\"\"\n    \n    try:\n        if dataset_name == \"tatsu-lab/alpaca\":\n            # English Alpaca\n            print(f\"Loading {dataset_name}...\")\n            dataset = load_dataset(dataset_name, split=f\"train[:{num_samples}]\")\n            \n            print(f\"✓ Loaded {len(dataset)} samples\")\n            print(f\"Columns: {dataset.column_names}\")\n            print(f\"Sample: {dataset[0]}\")\n            \n            def format_alpaca(example):\n                if example.get(\"input\", \"\").strip():\n                    text = f\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['input']}\\n\\n### Response:\\n{example['output']}\"\n                else:\n                    text = f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n{example['output']}\"\n                return {\"text\": text}\n            \n            dataset = dataset.map(format_alpaca, remove_columns=dataset.column_names)\n            \n        elif dataset_name == \"md-nishat-008/Bangla-Instruct\":\n            # Bengali - Native instruction data (100K samples)\n            print(f\"Loading {dataset_name}...\")\n            dataset = load_dataset(dataset_name, split=f\"train[:{num_samples}]\")\n            \n            print(f\"✓ Loaded {len(dataset)} samples\")\n            print(f\"Columns: {dataset.column_names}\")\n            print(f\"Sample: {dataset[0]}\")\n            \n            def format_bangla(example):\n                # QUIRK: Column is 'response' not 'output'\n                # Also filter out null responses\n                instruction = example.get('instruction', '').strip()\n                response = example.get('response', '').strip()\n                \n                if not instruction or not response:\n                    example[\"text\"] = \"\"\n                    example[\"valid\"] = False\n                else:\n                    text = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n{response}\"\n                    example[\"text\"] = text\n                    example[\"valid\"] = True\n                \n                return example\n            \n            dataset = dataset.map(format_bangla, remove_columns=dataset.column_names)\n            \n            # Filter out invalid samples\n            print(f\"Before filtering: {len(dataset)} samples\")\n            dataset = dataset.filter(lambda x: x[\"valid\"])\n            dataset = dataset.remove_columns([\"valid\"])\n            print(f\"After filtering: {len(dataset)} samples\")\n            \n        elif dataset_name == \"arbml/CIDAR\":\n            # Arabic - Human-reviewed culturally relevant (10K samples)\n            print(f\"Loading {dataset_name}...\")\n            \n            # CIDAR only has 10K samples total\n            actual_samples = min(num_samples, 10000)\n            dataset = load_dataset(dataset_name, split=f\"train[:{actual_samples}]\")\n            \n            print(f\"✓ Loaded {len(dataset)} samples\")\n            print(f\"Columns: {dataset.column_names}\")\n            print(f\"Sample: {dataset[0]}\")\n            \n            def format_arabic(example):\n                # CIDAR has: instruction, output, index\n                instruction = example.get('instruction', '').strip()\n                output = example.get('output', '').strip()\n                \n                if not instruction or not output:\n                    example[\"text\"] = \"\"\n                    example[\"valid\"] = False\n                else:\n                    text = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n{output}\"\n                    example[\"text\"] = text\n                    example[\"valid\"] = True\n                \n                return example\n            \n            dataset = dataset.map(format_arabic, remove_columns=dataset.column_names)\n            \n            # Filter out invalid samples\n            print(f\"Before filtering: {len(dataset)} samples\")\n            dataset = dataset.filter(lambda x: x[\"valid\"])\n            dataset = dataset.remove_columns([\"valid\"])\n            print(f\"After filtering: {len(dataset)} samples\")\n        \n        else:\n            raise ValueError(f\"Unknown dataset: {dataset_name}\")\n        \n        # Tokenize\n        def tokenize_function(examples):\n            return tokenizer(\n                examples[\"text\"],\n                truncation=True,\n                max_length=max_length,\n                padding=\"max_length\",\n                return_tensors=\"pt\"\n            )\n        \n        dataset = dataset.map(\n            tokenize_function,\n            batched=True,\n            remove_columns=[\"text\"],\n            desc=\"Tokenizing\"\n        )\n        dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n        \n        print(f\"✓ Dataset prepared: {len(dataset)} samples\")\n        return dataset\n        \n    except Exception as e:\n        print(f\"ERROR loading dataset: {e}\")\n        import traceback\n        traceback.print_exc()\n        raise\n\n# Load datasets\nprint(\"\\n\" + \"=\"*80)\nprint(\"PREPARING DATASETS\")\nprint(\"=\"*80)\n\nprint(\"\\n[1/3] Loading English (Alpaca)...\")\nen_dataset = prepare_dataset(\n    config.en_dataset, \n    num_samples=config.en_samples,\n    max_length=config.max_length\n)\n\nprint(\"\\n[2/3] Loading Bengali (Native Instructions)...\")\nbn_dataset = prepare_dataset(\n    config.bn_dataset,\n    num_samples=config.bn_samples,\n    max_length=config.max_length\n)\n\nprint(\"\\n[3/3] Loading Arabic (CIDAR - Human-Reviewed)...\")\nar_dataset = prepare_dataset(\n    config.ar_dataset,\n    num_samples=config.ar_samples,\n    max_length=config.max_length\n)\n\n# Create dataloaders\nen_dataloader = DataLoader(en_dataset, batch_size=config.batch_size, shuffle=False)\nbn_dataloader = DataLoader(bn_dataset, batch_size=config.batch_size, shuffle=True)\nar_dataloader = DataLoader(ar_dataset, batch_size=config.batch_size, shuffle=True)\n\nprint(f\"\\n{'='*80}\")\nprint(\"DATALOADER SUMMARY\")\nprint(f\"{'='*80}\")\nprint(f\"✓ English batches: {len(en_dataloader)}\")\nprint(f\"✓ Bengali batches: {len(bn_dataloader)}\")\nprint(f\"✓ Arabic batches: {len(ar_dataloader)}\")\nprint(f\"{'='*80}\\n\")\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# CELL 5: Test Set Evaluation\n# ============================================================================\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndef evaluate_on_test(model, test_dataloader, language_name):\n    \"\"\"Evaluate model on test set with proper causal language modeling\"\"\"\n    model.eval()\n    total_loss = 0\n    total_samples = 0\n    \n    with torch.no_grad():\n        for batch in tqdm(test_dataloader, desc=f\"Evaluating {language_name}\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            \n            # Shift labels for causal LM: predict next token\n            labels = input_ids.clone()\n            labels[labels == tokenizer.pad_token_id] = -100  # Ignore padding in loss\n            \n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n            \n            loss = outputs.loss\n            total_loss += loss.item()\n            total_samples += 1\n    \n    avg_loss = total_loss / total_samples\n    perplexity = torch.exp(torch.tensor(avg_loss))\n    \n    return {\n        \"loss\": avg_loss,\n        \"perplexity\": perplexity.item()\n    }\n\n# Prepare test sets (10% of training size for quick eval)\nprint(\"\\n\" + \"=\"*80)\nprint(\"PREPARING TEST SETS\")\nprint(\"=\"*80)\n\nen_test = prepare_dataset(config.en_dataset, num_samples=50, max_length=config.max_length)\nbn_test = prepare_dataset(config.bn_dataset, num_samples=500, max_length=config.max_length)\nar_test = prepare_dataset(config.ar_dataset, num_samples=500, max_length=config.max_length)\n\nen_test_loader = DataLoader(en_test, batch_size=config.batch_size, shuffle=False)\nbn_test_loader = DataLoader(bn_test, batch_size=config.batch_size, shuffle=False)\nar_test_loader = DataLoader(ar_test, batch_size=config.batch_size, shuffle=False)\n\n# Track performance at each stage\nperformance_tracking = {\n    \"after_en\": {},\n    \"after_bn\": {},\n    \"after_ar\": {}\n}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-09T21:53:48.662729Z\",\"iopub.execute_input\":\"2026-02-09T21:53:48.662987Z\",\"iopub.status.idle\":\"2026-02-09T21:53:48.669548Z\",\"shell.execute_reply.started\":\"2026-02-09T21:53:48.662966Z\",\"shell.execute_reply\":\"2026-02-09T21:53:48.669022Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# CELL 6: Gradient Extraction Function\n# ============================================================================\ndef extract_layer_gradients(model, batch, layers_to_track, device=\"cuda\"):\n    \"\"\"\n    Extract and aggregate gradients from specified Transformer layers.\n    \n    Returns:\n        dict: {layer_num: aggregated_gradient_tensor}\n    \"\"\"\n    model.zero_grad()\n    \n    # Forward pass\n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n    \n    outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n        labels=input_ids  # Causal LM loss\n    )\n    loss = outputs.loss\n    \n    # Backward pass\n    loss.backward()\n    \n    # Extract gradients from MLP layers\n    layer_grads = {layer: [] for layer in layers_to_track}\n    \n    for name, param in model.named_parameters():\n        if param.grad is None:\n            continue\n        \n        # Match pattern: model.layers.{X}.mlp\n        if \"model.layers.\" in name and \".mlp.\" in name:\n            try:\n                # Extract layer number\n                layer_num = int(name.split(\"model.layers.\")[1].split(\".\")[0])\n                \n                if layer_num in layers_to_track:\n                    # Flatten and store gradient\n                    layer_grads[layer_num].append(param.grad.detach().clone().flatten())\n            except (IndexError, ValueError):\n                continue\n    \n    # Concatenate all gradients per layer\n    aggregated_grads = {}\n    for layer, grads in layer_grads.items():\n        if grads:\n            aggregated_grads[layer] = torch.cat(grads)\n        else:\n            # Handle empty gradients (shouldn't happen but safety first)\n            print(f\"WARNING: No gradients found for layer {layer}\")\n            aggregated_grads[layer] = torch.zeros(1, device=device)\n    \n    return aggregated_grads, loss.item()\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# STAGE 1: TRAIN ON ENGLISH\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STAGE 1: TRAINING ON ENGLISH\")\nprint(\"=\"*80)\n\nmodel.train()\noptimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n\nfor step, batch in enumerate(tqdm(en_dataloader, desc=\"Training English\")):\n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n    \n    # Forward pass\n    outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n        labels=input_ids\n    )\n    \n    loss = outputs.loss\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    \n    if step % 10 == 0:\n        print(f\"Step {step}, Loss: {loss.item():.4f}\")\n\nprint(\"✓ English training complete\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-09T21:53:48.671322Z\",\"iopub.execute_input\":\"2026-02-09T21:53:48.671616Z\",\"iopub.status.idle\":\"2026-02-09T21:55:08.589163Z\",\"shell.execute_reply.started\":\"2026-02-09T21:53:48.671593Z\",\"shell.execute_reply\":\"2026-02-09T21:55:08.588582Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# CELL 7: Compute English Baseline Gradients\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"PHASE 1: COMPUTING ENGLISH BASELINE GRADIENT PROFILE\")\nprint(\"=\"*80)\n\nenglish_baseline_grads = {layer: None for layer in config.layers_to_track}\nen_losses = []\n\n# Sample subset of English data for baseline\nnum_baseline_batches = min(20, len(en_dataloader))\n\nprint(f\"Processing {num_baseline_batches} English batches...\")\n\nfor i, batch in enumerate(tqdm(en_dataloader, total=num_baseline_batches, desc=\"English baseline\")):\n    if i >= num_baseline_batches:\n        break\n    \n    layer_grads, loss = extract_layer_gradients(model, batch, config.layers_to_track)\n    en_losses.append(loss)\n    \n    # Accumulate gradients\n    for layer, grad in layer_grads.items():\n        if english_baseline_grads[layer] is None:\n            english_baseline_grads[layer] = grad.clone()\n        else:\n            english_baseline_grads[layer] += grad\n    \n    # CRITICAL: Clear gradients after extraction\n    model.zero_grad()\n    \n    # Clear memory\n    if i % 10 == 0:\n        torch.cuda.empty_cache()\n\n# Average the accumulated gradients\nfor layer in english_baseline_grads:\n    if english_baseline_grads[layer] is not None:\n        english_baseline_grads[layer] /= num_baseline_batches\n\nprint(f\"\\n✓ English baseline computed\")\nprint(f\"  Average loss: {np.mean(en_losses):.4f}\")\nprint(f\"  Gradient dimensions per layer:\")\nfor layer, grad in english_baseline_grads.items():\n    print(f\"    Layer {layer}: {grad.shape[0]:,} parameters\")\n\n# CRITICAL: Verify model is not corrupted\nprint(\"\\nVerifying model state...\")\nmodel.zero_grad()  # Clear all gradients\nhas_nan = False\nfor name, param in model.named_parameters():\n    if torch.isnan(param).any() or torch.isinf(param).any():\n        print(f\"ERROR: NaN/Inf in parameter {name}\")\n        has_nan = True\n\nif has_nan:\n    print(\"ERROR: Model corrupted, reloading...\")\n    # Reload model\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    model = AutoModelForCausalLM.from_pretrained(\n        config.model_name,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n        low_cpu_mem_usage=True,\n        attn_implementation=\"sdpa\"\n    )\n    if config.gradient_checkpointing:\n        model.gradient_checkpointing_enable()\n    model.train()\n    print(\"✓ Model reloaded\")\nelse:\n    print(\"✓ Model state is clean\")\n\n# Free memory\ndel en_dataset, en_dataloader\ngc.collect()\ntorch.cuda.empty_cache()\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nprint(\"\\n\" + \"=\"*80)\nprint(\"EVALUATION AFTER ENGLISH TRAINING\")\nprint(\"=\"*80)\n\nperformance_tracking[\"after_en\"][\"en\"] = evaluate_on_test(model, en_test_loader, \"English\")\nprint(f\"EN Test - Loss: {performance_tracking['after_en']['en']['loss']:.4f}, \"\n      f\"Perplexity: {performance_tracking['after_en']['en']['perplexity']:.2f}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-09T22:00:37.056928Z\",\"iopub.execute_input\":\"2026-02-09T22:00:37.057882Z\",\"iopub.status.idle\":\"2026-02-10T00:34:54.786249Z\",\"shell.execute_reply.started\":\"2026-02-09T22:00:37.057843Z\",\"shell.execute_reply\":\"2026-02-10T00:34:54.785500Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# CELL 8: BENGALI TRAINING WITH CONFLICT MONITORING\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"PHASE 2: BENGALI TRAINING WITH CONFLICT MONITORING (vs English baseline)\")\nprint(\"=\"*80)\n\n# Setup optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=50,\n    num_training_steps=config.total_steps\n)\n\n# Tracking structures\nconflict_history_bn = {layer: [] for layer in config.layers_to_track}\ntraining_metrics_bn = {\n    'steps': [],\n    'losses': [],\n    'peak_conflict_layers': []\n}\n\n# Training loop\nbn_dataloader_iter = iter(bn_dataloader)\nstep = 0\naccumulated_loss = 0\n\nprint(f\"Training on Bengali for {config.total_steps} steps (logging every {config.log_interval})...\")\n\nprogress_bar = tqdm(total=config.total_steps, desc=\"Bengali training\")\n\nwhile step < config.total_steps:\n    # Get next batch (cycle through dataset if needed)\n    try:\n        batch = next(bn_dataloader_iter)\n    except StopIteration:\n        bn_dataloader_iter = iter(bn_dataloader)\n        batch = next(bn_dataloader_iter)\n    \n    # Forward and backward\n    input_ids = batch[\"input_ids\"].to(\"cuda\")\n    attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n    \n    outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n        labels=input_ids\n    )\n    \n    loss = outputs.loss / config.gradient_accumulation\n\n    if loss.dtype != torch.bfloat16:\n        loss = loss.to(torch.bfloat16)\n    \n    # Check for NaN loss before backward\n    if torch.isnan(loss) or torch.isinf(loss):\n        print(f\"\\nWARNING: NaN loss at step {step}, skipping batch\")\n        step += 1\n        progress_bar.update(1)\n        continue\n    \n    loss.backward()\n    accumulated_loss += loss.item()\n    \n    # === CONFLICT MONITORING (extract gradients from CURRENT backward) ===\n    if step % config.log_interval == 0:\n        # Extract gradients directly from current backward pass (no second backward!)\n        layer_grads = {}\n        for name, param in model.named_parameters():\n            if param.grad is None:\n                continue\n            \n            if \".layers.\" in name and \".mlp.\" in name:\n                try:\n                    parts = name.split(\".layers.\")[1].split(\".\")\n                    layer_num = int(parts[0])\n                    \n                    if layer_num in config.layers_to_track:\n                        if layer_num not in layer_grads:\n                            layer_grads[layer_num] = []\n                        layer_grads[layer_num].append(param.grad.detach().clone().flatten())\n                except (IndexError, ValueError):\n                    continue\n        \n        # Concatenate gradients per layer\n        bn_layer_grads = {}\n        for layer, grads in layer_grads.items():\n            if grads:\n                bn_layer_grads[layer] = torch.cat(grads)\n        \n        # Compute cosine similarity with English baseline\n        layer_conflicts = {}\n        for layer in config.layers_to_track:\n            if layer in bn_layer_grads and english_baseline_grads[layer] is not None:\n                # Normalize gradients\n                en_grad_norm = F.normalize(english_baseline_grads[layer].unsqueeze(0), dim=1)\n                bn_grad_norm = F.normalize(bn_layer_grads[layer].unsqueeze(0), dim=1)\n                \n                # Cosine similarity\n                cos_sim = F.cosine_similarity(en_grad_norm, bn_grad_norm).item()\n                \n                # Store conflict metrics\n                conflict_history_bn[layer].append({\n                    'step': step,\n                    'cosine_similarity': cos_sim,\n                    'conflict_score': 1 - cos_sim,\n                    'bn_grad_norm': bn_layer_grads[layer].norm().item(),\n                    'en_grad_norm': english_baseline_grads[layer].norm().item()\n                })\n                \n                layer_conflicts[layer] = 1 - cos_sim\n        \n        # Find peak conflict layer\n        if layer_conflicts:\n            peak_conflict_layer = max(layer_conflicts, key=layer_conflicts.get)\n            training_metrics_bn['peak_conflict_layers'].append(peak_conflict_layer)\n            training_metrics_bn['steps'].append(step)\n            training_metrics_bn['losses'].append(accumulated_loss * config.gradient_accumulation)\n            \n            accumulated_loss = 0\n            \n            # Log\n            progress_bar.set_postfix({\n                'loss': f\"{training_metrics_bn['losses'][-1]:.4f}\",\n                'peak_layer': peak_conflict_layer,\n                'max_conflict': f\"{max(layer_conflicts.values()):.3f}\"\n            })\n    \n    # Optimizer step every gradient_accumulation steps\n    if (step + 1) % config.gradient_accumulation == 0:\n        # Gradient clipping\n        total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        \n        if torch.isnan(total_norm) or torch.isinf(total_norm):\n            print(f\"\\nWARNING: NaN gradients at step {step}, skipping update\")\n            optimizer.zero_grad()\n        else:\n            optimizer.step()\n            scheduler.step()\n            optimizer.zero_grad()\n    \n    step += 1\n    progress_bar.update(1)\n    \n    # Memory management\n    if step % 100 == 0:\n        torch.cuda.empty_cache()\n\nprogress_bar.close()\nprint(\"\\n✓ Bengali training complete\")\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n# [After Bengali training - add this checkpoint]\nprint(\"\\n\" + \"=\"*80)\nprint(\"EVALUATION AFTER BENGALI TRAINING\")\nprint(\"=\"*80)\n\nperformance_tracking[\"after_bn\"][\"en\"] = evaluate_on_test(model, en_test_loader, \"English\")\nperformance_tracking[\"after_bn\"][\"bn\"] = evaluate_on_test(model, bn_test_loader, \"Bengali\")\n\nprint(f\"EN Test - Loss: {performance_tracking['after_bn']['en']['loss']:.4f}, \"\n      f\"Perplexity: {performance_tracking['after_bn']['en']['perplexity']:.2f}\")\nprint(f\"BN Test - Loss: {performance_tracking['after_bn']['bn']['loss']:.4f}, \"\n      f\"Perplexity: {performance_tracking['after_bn']['bn']['perplexity']:.2f}\")\n\nen_degradation = ((performance_tracking['after_bn']['en']['perplexity'] - \n                   performance_tracking['after_en']['en']['perplexity']) / \n                  performance_tracking['after_en']['en']['perplexity']) * 100\n\nprint(f\"\\n⚠️  EN Performance Degradation: {en_degradation:+.1f}%\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-10T00:34:54.787874Z\",\"iopub.execute_input\":\"2026-02-10T00:34:54.788158Z\",\"iopub.status.idle\":\"2026-02-10T00:36:26.131361Z\",\"shell.execute_reply.started\":\"2026-02-10T00:34:54.788138Z\",\"shell.execute_reply\":\"2026-02-10T00:36:26.130565Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nprint(\"\\n\" + \"=\"*80)\nprint(\"PHASE 3: COMPUTING BENGALI BASELINE GRADIENT PROFILE (post-training)\")\nprint(\"=\"*80)\n\nbengali_baseline_grads = {layer: None for layer in config.layers_to_track}\nbn_baseline_losses = []\n\nnum_baseline_batches = min(20, len(bn_dataloader))\n\nfor i, batch in enumerate(tqdm(bn_dataloader, total=num_baseline_batches)):\n    if i >= num_baseline_batches:\n        break\n    \n    layer_grads, loss = extract_layer_gradients(model, batch, config.layers_to_track)\n    bn_baseline_losses.append(loss)\n    \n    for layer, grad in layer_grads.items():\n        if bengali_baseline_grads[layer] is None:\n            bengali_baseline_grads[layer] = grad.clone()\n        else:\n            bengali_baseline_grads[layer] += grad\n    \n    model.zero_grad()\n\n# Average\nfor layer in bengali_baseline_grads:\n    if bengali_baseline_grads[layer] is not None:\n        bengali_baseline_grads[layer] /= num_baseline_batches\n\nprint(f\"✓ Bengali baseline computed from trained model\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-10T00:36:26.133038Z\",\"iopub.execute_input\":\"2026-02-10T00:36:26.133657Z\",\"iopub.status.idle\":\"2026-02-10T03:08:23.557549Z\",\"shell.execute_reply.started\":\"2026-02-10T00:36:26.133634Z\",\"shell.execute_reply\":\"2026-02-10T03:08:23.556962Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# CELL 9: ARABIC TRAINING WITH CONFLICT MONITORING\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"PHASE 4: ARABIC TRAINING WITH CONFLICT MONITORING (vs Bengali baseline)\")\nprint(\"=\"*80)\n\n# RE-INITIALIZE optimizer (fresh training phase)\noptimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=50,\n    num_training_steps=config.total_steps\n)\n\n# Tracking structures\nconflict_history_ar = {layer: [] for layer in config.layers_to_track}\ntraining_metrics_ar = {\n    'steps': [],\n    'losses': [],\n    'peak_conflict_layers': []\n}\n\n# Training loop\nar_dataloader_iter = iter(ar_dataloader)\nstep = 0\naccumulated_loss = 0\n\nprint(f\"Training on Arabic for {config.total_steps} steps (logging every {config.log_interval})...\")\n\nprogress_bar = tqdm(total=config.total_steps, desc=\"Arabic training\")\n\nwhile step < config.total_steps:\n    # Get next batch (cycle through dataset if needed)\n    try:\n        batch = next(ar_dataloader_iter)\n    except StopIteration:\n        ar_dataloader_iter = iter(ar_dataloader)\n        batch = next(ar_dataloader_iter)\n    \n    # Forward and backward\n    input_ids = batch[\"input_ids\"].to(\"cuda\")\n    attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n    \n    outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n        labels=input_ids\n    )\n    \n    loss = outputs.loss / config.gradient_accumulation\n\n    if loss.dtype != torch.bfloat16:\n        loss = loss.to(torch.bfloat16)\n    \n    # Check for NaN loss before backward\n    if torch.isnan(loss) or torch.isinf(loss):\n        print(f\"\\nWARNING: NaN loss at step {step}, skipping batch\")\n        step += 1\n        progress_bar.update(1)\n        continue\n    \n    loss.backward()\n    accumulated_loss += loss.item()\n    \n    # === CONFLICT MONITORING (extract gradients from CURRENT backward) ===\n    if step % config.log_interval == 0:\n        # Extract gradients directly from current backward pass (no second backward!)\n        layer_grads = {}\n        for name, param in model.named_parameters():\n            if param.grad is None:\n                continue\n            \n            if \".layers.\" in name and \".mlp.\" in name:\n                try:\n                    parts = name.split(\".layers.\")[1].split(\".\")\n                    layer_num = int(parts[0])\n                    \n                    if layer_num in config.layers_to_track:\n                        if layer_num not in layer_grads:\n                            layer_grads[layer_num] = []\n                        layer_grads[layer_num].append(param.grad.detach().clone().flatten())\n                except (IndexError, ValueError):\n                    continue\n        \n        # Concatenate gradients per layer\n        ar_layer_grads = {}\n        for layer, grads in layer_grads.items():\n            if grads:\n                ar_layer_grads[layer] = torch.cat(grads)\n        \n        # Compute cosine similarity with BENGALI baseline\n        layer_conflicts = {}\n        for layer in config.layers_to_track:\n            if layer in ar_layer_grads and bengali_baseline_grads[layer] is not None:\n                # Normalize gradients\n                bn_grad_norm = F.normalize(bengali_baseline_grads[layer].unsqueeze(0), dim=1)\n                ar_grad_norm = F.normalize(ar_layer_grads[layer].unsqueeze(0), dim=1)\n                \n                # Cosine similarity\n                cos_sim = F.cosine_similarity(bn_grad_norm, ar_grad_norm).item()\n                \n                # Store conflict metrics\n                conflict_history_ar[layer].append({\n                    'step': step,\n                    'cosine_similarity': cos_sim,\n                    'conflict_score': 1 - cos_sim,\n                    'bn_grad_norm': ar_layer_grads[layer].norm().item(),  # This is AR grad norm (variable name kept for consistency)\n                    'en_grad_norm': bengali_baseline_grads[layer].norm().item()  # This is BN baseline norm\n                })\n                \n                layer_conflicts[layer] = 1 - cos_sim\n        \n        # Find peak conflict layer\n        if layer_conflicts:\n            peak_conflict_layer = max(layer_conflicts, key=layer_conflicts.get)\n            training_metrics_ar['peak_conflict_layers'].append(peak_conflict_layer)\n            training_metrics_ar['steps'].append(step)\n            training_metrics_ar['losses'].append(accumulated_loss * config.gradient_accumulation)\n            \n            accumulated_loss = 0\n            \n            # Log\n            progress_bar.set_postfix({\n                'loss': f\"{training_metrics_ar['losses'][-1]:.4f}\",\n                'peak_layer': peak_conflict_layer,\n                'max_conflict': f\"{max(layer_conflicts.values()):.3f}\"\n            })\n    \n    # Optimizer step every gradient_accumulation steps\n    if (step + 1) % config.gradient_accumulation == 0:\n        # Gradient clipping\n        total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        \n        if torch.isnan(total_norm) or torch.isinf(total_norm):\n            print(f\"\\nWARNING: NaN gradients at step {step}, skipping update\")\n            optimizer.zero_grad()\n        else:\n            optimizer.step()\n            scheduler.step()\n            optimizer.zero_grad()\n    \n    step += 1\n    progress_bar.update(1)\n    \n    # Memory management\n    if step % 100 == 0:\n        torch.cuda.empty_cache()\n\nprogress_bar.close()\nprint(\"\\n✓ Arabic training complete\")\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nprint(\"\\n\" + \"=\"*80)\nprint(\"EVALUATION AFTER ARABIC TRAINING\")\nprint(\"=\"*80)\n\nperformance_tracking[\"after_ar\"][\"en\"] = evaluate_on_test(model, en_test_loader, \"English\")\nperformance_tracking[\"after_ar\"][\"bn\"] = evaluate_on_test(model, bn_test_loader, \"Bengali\")\nperformance_tracking[\"after_ar\"][\"ar\"] = evaluate_on_test(model, ar_test_loader, \"Arabic\")\n\nprint(f\"EN Test - Loss: {performance_tracking['after_ar']['en']['loss']:.4f}, \"\n      f\"Perplexity: {performance_tracking['after_ar']['en']['perplexity']:.2f}\")\nprint(f\"BN Test - Loss: {performance_tracking['after_ar']['bn']['loss']:.4f}, \"\n      f\"Perplexity: {performance_tracking['after_ar']['bn']['perplexity']:.2f}\")\nprint(f\"AR Test - Loss: {performance_tracking['after_ar']['ar']['loss']:.4f}, \"\n      f\"Perplexity: {performance_tracking['after_ar']['ar']['perplexity']:.2f}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-10T03:08:23.559175Z\",\"iopub.execute_input\":\"2026-02-10T03:08:23.559409Z\",\"iopub.status.idle\":\"2026-02-10T03:08:27.451737Z\",\"shell.execute_reply.started\":\"2026-02-10T03:08:23.559389Z\",\"shell.execute_reply\":\"2026-02-10T03:08:27.451028Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# COMBINED VISUALIZATION: EN→BN→AR Sequential Transfer Analysis\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"PHASE 5: COMBINED ANALYSIS - EN→BN→AR CONFLICT EVOLUTION\")\nprint(\"=\"*80)\n\nfig = plt.figure(figsize=(20, 14))\ngs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n\nfig.suptitle('Sequential Transfer Analysis: EN→BN→AR\\nNon-Stationary Gradient Conflict Migration', \n             fontsize=18, fontweight='bold', y=0.98)\n\n# ============================================================================\n# ROW 1: CONFLICT EVOLUTION BY LAYER (BOTH STAGES)\n# ============================================================================\n\n# Plot 1: EN→BN Conflict Evolution\nax1 = fig.add_subplot(gs[0, 0])\nfor layer in config.layers_to_track:\n    steps = [h['step'] for h in conflict_history_bn[layer]]\n    conflicts = [h['conflict_score'] for h in conflict_history_bn[layer]]\n    ax1.plot(steps, conflicts, marker='o', markersize=4, label=f'Layer {layer}', linewidth=2, alpha=0.8)\n\nax1.set_xlabel('Training Steps', fontsize=11)\nax1.set_ylabel('Conflict Score (1 - cosine_sim)', fontsize=11)\nax1.set_title('Stage 1: EN→BN Gradient Conflicts', fontsize=13, fontweight='bold')\nax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9, ncol=1)\nax1.grid(True, alpha=0.3)\nax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.4, linewidth=1.5)\nax1.set_ylim([0, 1])\n\n# Plot 2: BN→AR Conflict Evolution\nax2 = fig.add_subplot(gs[0, 1])\nfor layer in config.layers_to_track:\n    steps = [h['step'] for h in conflict_history_ar[layer]]\n    conflicts = [h['conflict_score'] for h in conflict_history_ar[layer]]\n    ax2.plot(steps, conflicts, marker='s', markersize=4, label=f'Layer {layer}', linewidth=2, alpha=0.8)\n\nax2.set_xlabel('Training Steps', fontsize=11)\nax2.set_ylabel('Conflict Score (1 - cosine_sim)', fontsize=11)\nax2.set_title('Stage 2: BN→AR Gradient Conflicts', fontsize=13, fontweight='bold')\nax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9, ncol=1)\nax2.grid(True, alpha=0.3)\nax2.axhline(y=0.5, color='red', linestyle='--', alpha=0.4, linewidth=1.5)\nax2.set_ylim([0, 1])\n\n# Plot 3: Side-by-Side Comparison (Final Conflicts)\nax3 = fig.add_subplot(gs[0, 2])\nfinal_conflicts_bn = {}\nfinal_conflicts_ar = {}\n\nfor layer in config.layers_to_track:\n    if conflict_history_bn[layer]:\n        final_conflicts_bn[layer] = conflict_history_bn[layer][-1]['conflict_score']\n    if conflict_history_ar[layer]:\n        final_conflicts_ar[layer] = conflict_history_ar[layer][-1]['conflict_score']\n\nx = np.arange(len(config.layers_to_track))\nwidth = 0.35\n\nbars1 = ax3.bar(x - width/2, [final_conflicts_bn.get(l, 0) for l in config.layers_to_track], \n                width, label='EN→BN', color='steelblue', alpha=0.8)\nbars2 = ax3.bar(x + width/2, [final_conflicts_ar.get(l, 0) for l in config.layers_to_track], \n                width, label='BN→AR', color='coral', alpha=0.8)\n\nax3.set_xlabel('Layer', fontsize=11)\nax3.set_ylabel('Final Conflict Score', fontsize=11)\nax3.set_title('Final Conflict Comparison', fontsize=13, fontweight='bold')\nax3.set_xticks(x)\nax3.set_xticklabels([f'L{l}' for l in config.layers_to_track])\nax3.legend(fontsize=10)\nax3.grid(True, alpha=0.3, axis='y')\n\n# ============================================================================\n# ROW 2: PEAK CONFLICT LAYER MIGRATION\n# ============================================================================\n\n# Plot 4: EN→BN Peak Migration\nax4 = fig.add_subplot(gs[1, 0])\ncheckpoint_indices_bn = list(range(len(training_metrics_bn['peak_conflict_layers'])))\nax4.plot(checkpoint_indices_bn, training_metrics_bn['peak_conflict_layers'], \n         marker='o', markersize=8, linewidth=2.5, color='darkblue', label='Peak Layer')\nax4.fill_between(checkpoint_indices_bn, training_metrics_bn['peak_conflict_layers'], \n                  alpha=0.2, color='blue')\n\nax4.set_xlabel(f'Checkpoint (every {config.log_interval} steps)', fontsize=11)\nax4.set_ylabel('Layer with Peak Conflict', fontsize=11)\nax4.set_title('Stage 1: EN→BN Peak Migration', fontsize=13, fontweight='bold')\nax4.set_yticks(config.layers_to_track)\nax4.grid(True, alpha=0.3)\nax4.legend(fontsize=10)\n\n# Highlight migration\ninitial_peak_bn = training_metrics_bn['peak_conflict_layers'][0]\nfinal_peak_bn = training_metrics_bn['peak_conflict_layers'][-1]\nax4.axhline(y=initial_peak_bn, color='blue', linestyle='--', alpha=0.5, linewidth=2)\nax4.axhline(y=final_peak_bn, color='green', linestyle='--', alpha=0.5, linewidth=2)\nax4.text(0.02, 0.98, f'Initial: L{initial_peak_bn}\\nFinal: L{final_peak_bn}', \n         transform=ax4.transAxes, fontsize=10, verticalalignment='top',\n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n# Plot 5: BN→AR Peak Migration\nax5 = fig.add_subplot(gs[1, 1])\ncheckpoint_indices_ar = list(range(len(training_metrics_ar['peak_conflict_layers'])))\nax5.plot(checkpoint_indices_ar, training_metrics_ar['peak_conflict_layers'], \n         marker='s', markersize=8, linewidth=2.5, color='darkred', label='Peak Layer')\nax5.fill_between(checkpoint_indices_ar, training_metrics_ar['peak_conflict_layers'], \n                  alpha=0.2, color='red')\n\nax5.set_xlabel(f'Checkpoint (every {config.log_interval} steps)', fontsize=11)\nax5.set_ylabel('Layer with Peak Conflict', fontsize=11)\nax5.set_title('Stage 2: BN→AR Peak Migration', fontsize=13, fontweight='bold')\nax5.set_yticks(config.layers_to_track)\nax5.grid(True, alpha=0.3)\nax5.legend(fontsize=10)\n\n# Highlight migration\ninitial_peak_ar = training_metrics_ar['peak_conflict_layers'][0]\nfinal_peak_ar = training_metrics_ar['peak_conflict_layers'][-1]\nax5.axhline(y=initial_peak_ar, color='blue', linestyle='--', alpha=0.5, linewidth=2)\nax5.axhline(y=final_peak_ar, color='green', linestyle='--', alpha=0.5, linewidth=2)\nax5.text(0.02, 0.98, f'Initial: L{initial_peak_ar}\\nFinal: L{final_peak_ar}', \n         transform=ax5.transAxes, fontsize=10, verticalalignment='top',\n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n# Plot 6: Combined Peak Migration Journey\nax6 = fig.add_subplot(gs[1, 2])\n\n# Create continuous timeline\ntotal_checkpoints_bn = len(training_metrics_bn['peak_conflict_layers'])\ntotal_checkpoints_ar = len(training_metrics_ar['peak_conflict_layers'])\ntimeline = list(range(total_checkpoints_bn + total_checkpoints_ar))\n\ncombined_peaks = (training_metrics_bn['peak_conflict_layers'] + \n                  training_metrics_ar['peak_conflict_layers'])\n\n# Plot with color coding for stages\nax6.plot(timeline[:total_checkpoints_bn], combined_peaks[:total_checkpoints_bn], \n         marker='o', markersize=6, linewidth=2.5, color='steelblue', label='EN→BN Stage')\nax6.plot(timeline[total_checkpoints_bn-1:], combined_peaks[total_checkpoints_bn-1:], \n         marker='s', markersize=6, linewidth=2.5, color='coral', label='BN→AR Stage')\n\n# Mark stage transition\nax6.axvline(x=total_checkpoints_bn, color='black', linestyle='--', linewidth=2, \n            alpha=0.7, label='Stage Transition')\n\nax6.set_xlabel('Combined Timeline (checkpoints)', fontsize=11)\nax6.set_ylabel('Layer with Peak Conflict', fontsize=11)\nax6.set_title('Full Journey: Peak Conflict Migration', fontsize=13, fontweight='bold')\nax6.set_yticks(config.layers_to_track)\nax6.legend(fontsize=10)\nax6.grid(True, alpha=0.3)\n\n# ============================================================================\n# ROW 3: TRAINING DYNAMICS\n# ============================================================================\n\n# Plot 7: Training Loss Comparison\nax7 = fig.add_subplot(gs[2, 0])\nax7.plot(training_metrics_bn['steps'], training_metrics_bn['losses'], \n         linewidth=2.5, color='steelblue', label='EN→BN', alpha=0.8)\nax7_twin = ax7.twinx()\nax7_twin.plot(training_metrics_ar['steps'], training_metrics_ar['losses'], \n              linewidth=2.5, color='coral', label='BN→AR', alpha=0.8)\n\nax7.set_xlabel('Training Steps', fontsize=11)\nax7.set_ylabel('EN→BN Loss', fontsize=11, color='steelblue')\nax7_twin.set_ylabel('BN→AR Loss', fontsize=11, color='coral')\nax7.set_title('Training Loss Trajectories', fontsize=13, fontweight='bold')\nax7.tick_params(axis='y', labelcolor='steelblue')\nax7_twin.tick_params(axis='y', labelcolor='coral')\nax7.grid(True, alpha=0.3)\n\n# Combined legend\nlines1, labels1 = ax7.get_legend_handles_labels()\nlines2, labels2 = ax7_twin.get_legend_handles_labels()\nax7.legend(lines1 + lines2, labels1 + labels2, loc='upper right', fontsize=10)\n\n# Plot 8: Gradient Magnitude Heatmap (EN→BN)\nax8 = fig.add_subplot(gs[2, 1])\ngrad_magnitudes_bn = np.zeros((len(config.layers_to_track), len(conflict_history_bn[config.layers_to_track[0]])))\n\nfor i, layer in enumerate(config.layers_to_track):\n    for j, hist in enumerate(conflict_history_bn[layer]):\n        grad_magnitudes_bn[i, j] = hist['bn_grad_norm']\n\nim1 = ax8.imshow(grad_magnitudes_bn, aspect='auto', cmap='YlOrRd', interpolation='nearest')\nax8.set_yticks(range(len(config.layers_to_track)))\nax8.set_yticklabels([f'L{l}' for l in config.layers_to_track])\nax8.set_xlabel(f'Checkpoint (every {config.log_interval} steps)', fontsize=11)\nax8.set_ylabel('Layer', fontsize=11)\nax8.set_title('EN→BN Gradient Magnitude Heatmap', fontsize=13, fontweight='bold')\nplt.colorbar(im1, ax=ax8, label='Gradient Norm')\n\n# Plot 9: Gradient Magnitude Heatmap (BN→AR)\nax9 = fig.add_subplot(gs[2, 2])\ngrad_magnitudes_ar = np.zeros((len(config.layers_to_track), len(conflict_history_ar[config.layers_to_track[0]])))\n\nfor i, layer in enumerate(config.layers_to_track):\n    for j, hist in enumerate(conflict_history_ar[layer]):\n        grad_magnitudes_ar[i, j] = hist['bn_grad_norm']  # This stores AR grad norm (variable name is misleading from original code)\n\nim2 = ax9.imshow(grad_magnitudes_ar, aspect='auto', cmap='YlOrRd', interpolation='nearest')\nax9.set_yticks(range(len(config.layers_to_track)))\nax9.set_yticklabels([f'L{l}' for l in config.layers_to_track])\nax9.set_xlabel(f'Checkpoint (every {config.log_interval} steps)', fontsize=11)\nax9.set_ylabel('Layer', fontsize=11)\nax9.set_title('BN→AR Gradient Magnitude Heatmap', fontsize=13, fontweight='bold')\nplt.colorbar(im2, ax=ax9, label='Gradient Norm')\n\nplt.savefig('combined_en_bn_ar_analysis.png', dpi=300, bbox_inches='tight')\nprint(\"\\n✓ Combined visualization saved: combined_en_bn_ar_analysis.png\")\nplt.show()\n\n# ============================================================================\n# SUMMARY STATISTICS TABLE\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"SEQUENTIAL TRANSFER SUMMARY\")\nprint(\"=\"*80)\n\nprint(\"\\n📊 STAGE 1: EN→BN\")\nprint(f\"  ├─ Initial peak layer: {initial_peak_bn}\")\nprint(f\"  ├─ Final peak layer: {final_peak_bn}\")\nprint(f\"  ├─ Layer migration distance: {abs(final_peak_bn - initial_peak_bn)}\")\nmigrations_bn = sum(1 for i in range(1, len(training_metrics_bn['peak_conflict_layers'])) \n                    if training_metrics_bn['peak_conflict_layers'][i] != training_metrics_bn['peak_conflict_layers'][i-1])\nprint(f\"  ├─ Number of peak migrations: {migrations_bn}\")\nprint(f\"  └─ Final loss: {training_metrics_bn['losses'][-1]:.4f}\")\n\nprint(\"\\n📊 STAGE 2: BN→AR\")\nprint(f\"  ├─ Initial peak layer: {initial_peak_ar}\")\nprint(f\"  ├─ Final peak layer: {final_peak_ar}\")\nprint(f\"  ├─ Layer migration distance: {abs(final_peak_ar - initial_peak_ar)}\")\nmigrations_ar = sum(1 for i in range(1, len(training_metrics_ar['peak_conflict_layers'])) \n                    if training_metrics_ar['peak_conflict_layers'][i] != training_metrics_ar['peak_conflict_layers'][i-1])\nprint(f\"  ├─ Number of peak migrations: {migrations_ar}\")\nprint(f\"  └─ Final loss: {training_metrics_ar['losses'][-1]:.4f}\")\n\nprint(\"\\n🔬 CROSS-STAGE COMPARISON\")\nprint(f\"  ├─ EN→BN total migration events: {migrations_bn}\")\nprint(f\"  ├─ BN→AR total migration events: {migrations_ar}\")\nprint(f\"  ├─ Pattern consistency: {'Similar' if abs(migrations_bn - migrations_ar) <= 2 else 'Different'}\")\n\n# Check if conflicts are more severe in one stage\navg_conflict_bn = np.mean([h['conflict_score'] for layer in config.layers_to_track for h in conflict_history_bn[layer]])\navg_conflict_ar = np.mean([h['conflict_score'] for layer in config.layers_to_track for h in conflict_history_ar[layer]])\nprint(f\"  ├─ Average EN→BN conflict: {avg_conflict_bn:.4f}\")\nprint(f\"  ├─ Average BN→AR conflict: {avg_conflict_ar:.4f}\")\nprint(f\"  └─ More severe stage: {'EN→BN' if avg_conflict_bn > avg_conflict_ar else 'BN→AR'}\")\n\nprint(\"\\n\" + \"=\"*80)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-10T03:08:27.452575Z\",\"iopub.execute_input\":\"2026-02-10T03:08:27.452819Z\",\"iopub.status.idle\":\"2026-02-10T03:08:27.471951Z\",\"shell.execute_reply.started\":\"2026-02-10T03:08:27.452798Z\",\"shell.execute_reply\":\"2026-02-10T03:08:27.471273Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# CELL 11: Quantitative Validation Metrics (EN→BN→AR)\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"VALIDATION RESULTS - SEQUENTIAL TRANSFER ANALYSIS\")\nprint(\"=\"*80)\n\n# ============================================================================\n# STAGE 1: EN→BN ANALYSIS\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"STAGE 1: EN→BN VALIDATION\")\nprint(\"=\"*80)\n\npeak_layers_bn = training_metrics_bn['peak_conflict_layers']\nunique_peaks_bn = set(peak_layers_bn)\nmigrations_bn = sum(1 for i in range(1, len(peak_layers_bn)) if peak_layers_bn[i] != peak_layers_bn[i-1])\n\nconflict_variance_bn = {}\nfor layer in config.layers_to_track:\n    conflicts = [h['conflict_score'] for h in conflict_history_bn[layer]]\n    conflict_variance_bn[layer] = np.var(conflicts)\n\nhigh_variance_layers_bn = sorted(conflict_variance_bn.items(), key=lambda x: x[1], reverse=True)[:3]\n\nprint(f\"\\n📊 KEY FINDINGS (EN→BN):\")\nprint(f\"  ├─ Peak conflict migrated {migrations_bn} times across {len(peak_layers_bn)} checkpoints\")\nprint(f\"  ├─ {len(unique_peaks_bn)} unique layers experienced peak conflict\")\nprint(f\"  ├─ Initial peak: Layer {peak_layers_bn[0]}\")\nprint(f\"  └─ Final peak: Layer {peak_layers_bn[-1]}\")\n\nprint(f\"\\n📈 MOST NON-STATIONARY LAYERS (EN→BN):\")\nfor layer, variance in high_variance_layers_bn:\n    print(f\"  ├─ Layer {layer}: variance = {variance:.4f}\")\n\n# Hypothesis validation for EN→BN\nprint(f\"\\n🎯 HYPOTHESIS VALIDATION (EN→BN):\")\nhypothesis_validated_bn = False\n\nlayer_distance_bn = abs(peak_layers_bn[-1] - peak_layers_bn[0])\nif layer_distance_bn >= 4:\n    print(f\"  ✅ STRONG: Peak conflict migrated {layer_distance_bn} layers (shallow→deep or vice versa)\")\n    hypothesis_validated_bn = True\nelif migrations_bn >= 5:\n    print(f\"  ✅ MODERATE: Peak conflict oscillated across {migrations_bn} layer transitions\")\n    hypothesis_validated_bn = True\nelse:\n    print(f\"  ⚠️  WEAK: Limited peak migration detected ({migrations_bn} transitions)\")\n\nmax_variance_bn = max(conflict_variance_bn.values())\nmin_variance_bn = min(conflict_variance_bn.values())\nif max_variance_bn / min_variance_bn > 5:\n    print(f\"  ✅ Conflict variance highly non-uniform (ratio: {max_variance_bn/min_variance_bn:.2f}x)\")\n    hypothesis_validated_bn = True\nelse:\n    print(f\"  ⚠️  Conflict variance relatively uniform (ratio: {max_variance_bn/min_variance_bn:.2f}x)\")\n\nfor layer in config.layers_to_track:\n    conflicts = [h['conflict_score'] for h in conflict_history_bn[layer]]\n    if len(conflicts) >= 3:\n        early_avg = np.mean(conflicts[:3])\n        late_avg = np.mean(conflicts[-3:])\n        if late_avg > early_avg * 1.5:\n            print(f\"  ✅ Layer {layer} conflict increased {(late_avg/early_avg - 1)*100:.1f}% (emergent bottleneck)\")\n            hypothesis_validated_bn = True\n\n# ============================================================================\n# STAGE 2: BN→AR ANALYSIS\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"STAGE 2: BN→AR VALIDATION\")\nprint(\"=\"*80)\n\npeak_layers_ar = training_metrics_ar['peak_conflict_layers']\nunique_peaks_ar = set(peak_layers_ar)\nmigrations_ar = sum(1 for i in range(1, len(peak_layers_ar)) if peak_layers_ar[i] != peak_layers_ar[i-1])\n\nconflict_variance_ar = {}\nfor layer in config.layers_to_track:\n    conflicts = [h['conflict_score'] for h in conflict_history_ar[layer]]\n    conflict_variance_ar[layer] = np.var(conflicts)\n\nhigh_variance_layers_ar = sorted(conflict_variance_ar.items(), key=lambda x: x[1], reverse=True)[:3]\n\nprint(f\"\\n📊 KEY FINDINGS (BN→AR):\")\nprint(f\"  ├─ Peak conflict migrated {migrations_ar} times across {len(peak_layers_ar)} checkpoints\")\nprint(f\"  ├─ {len(unique_peaks_ar)} unique layers experienced peak conflict\")\nprint(f\"  ├─ Initial peak: Layer {peak_layers_ar[0]}\")\nprint(f\"  └─ Final peak: Layer {peak_layers_ar[-1]}\")\n\nprint(f\"\\n📈 MOST NON-STATIONARY LAYERS (BN→AR):\")\nfor layer, variance in high_variance_layers_ar:\n    print(f\"  ├─ Layer {layer}: variance = {variance:.4f}\")\n\n# Hypothesis validation for BN→AR\nprint(f\"\\n🎯 HYPOTHESIS VALIDATION (BN→AR):\")\nhypothesis_validated_ar = False\n\nlayer_distance_ar = abs(peak_layers_ar[-1] - peak_layers_ar[0])\nif layer_distance_ar >= 4:\n    print(f\"  ✅ STRONG: Peak conflict migrated {layer_distance_ar} layers (shallow→deep or vice versa)\")\n    hypothesis_validated_ar = True\nelif migrations_ar >= 5:\n    print(f\"  ✅ MODERATE: Peak conflict oscillated across {migrations_ar} layer transitions\")\n    hypothesis_validated_ar = True\nelse:\n    print(f\"  ⚠️  WEAK: Limited peak migration detected ({migrations_ar} transitions)\")\n\nmax_variance_ar = max(conflict_variance_ar.values())\nmin_variance_ar = min(conflict_variance_ar.values())\nif max_variance_ar / min_variance_ar > 5:\n    print(f\"  ✅ Conflict variance highly non-uniform (ratio: {max_variance_ar/min_variance_ar:.2f}x)\")\n    hypothesis_validated_ar = True\nelse:\n    print(f\"  ⚠️  Conflict variance relatively uniform (ratio: {max_variance_ar/min_variance_ar:.2f}x)\")\n\nfor layer in config.layers_to_track:\n    conflicts = [h['conflict_score'] for h in conflict_history_ar[layer]]\n    if len(conflicts) >= 3:\n        early_avg = np.mean(conflicts[:3])\n        late_avg = np.mean(conflicts[-3:])\n        if late_avg > early_avg * 1.5:\n            print(f\"  ✅ Layer {layer} conflict increased {(late_avg/early_avg - 1)*100:.1f}% (emergent bottleneck)\")\n            hypothesis_validated_ar = True\n\n# ============================================================================\n# COMBINED VALIDATION SUMMARY\n# ============================================================================\nprint(f\"\\n{'='*80}\")\nprint(\"🏆 OVERALL HYPOTHESIS VALIDATION\")\nprint(\"=\"*80)\n\nif hypothesis_validated_bn and hypothesis_validated_ar:\n    print(\"✅ STRONGLY VALIDATED: Both EN→BN and BN→AR show NON-STATIONARY conflicts\")\n    print(\"   → Static expert allocation is SUBOPTIMAL across sequential transfer\")\n    print(\"   → CADEA paper premise is SOUND for multilingual scenarios\")\nelif hypothesis_validated_bn or hypothesis_validated_ar:\n    print(\"✅ PARTIALLY VALIDATED: At least one stage shows NON-STATIONARY conflicts\")\n    validated_stage = \"EN→BN\" if hypothesis_validated_bn else \"BN→AR\"\n    print(f\"   → {validated_stage} demonstrates non-stationarity\")\n    print(\"   → CADEA may be beneficial but effect varies by language pair\")\nelse:\n    print(\"❌ HYPOTHESIS WEAK: Both stages show relatively stationary conflicts\")\n    print(\"   → Consider longer training, different language pairs, or architecture\")\n\nprint(\"=\"*80)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2026-02-10T03:08:27.472878Z\",\"iopub.execute_input\":\"2026-02-10T03:08:27.473089Z\",\"iopub.status.idle\":\"2026-02-10T03:08:27.498816Z\",\"shell.execute_reply.started\":\"2026-02-10T03:08:27.473071Z\",\"shell.execute_reply\":\"2026-02-10T03:08:27.498294Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# CELL 12: Export Data for Paper\n# ============================================================================\nimport json\n\n# Save detailed results for both stages\nresults = {\n    'config': {\n        'model': config.model_name,\n        'languages': ['English', 'Bengali', 'Arabic'],\n        'transfer_sequence': 'EN→BN→AR',\n        'total_steps_per_stage': config.total_steps,\n        'layers_tracked': config.layers_to_track,\n        'learning_rate': config.learning_rate,\n        'batch_size': config.batch_size,\n        'gradient_accumulation': config.gradient_accumulation\n    },\n    \n    'stage_1_en_bn': {\n        'metrics': {\n            'peak_migrations': int(migrations_bn),\n            'unique_peak_layers': list(unique_peaks_bn),\n            'initial_peak': int(peak_layers_bn[0]),\n            'final_peak': int(peak_layers_bn[-1]),\n            'layer_distance': int(layer_distance_bn),\n            'hypothesis_validated': bool(hypothesis_validated_bn)\n        },\n        'conflict_history': {\n            str(layer): [\n                {k: float(v) if isinstance(v, (int, float, np.number)) else int(v) \n                 for k, v in h.items()}\n                for h in history\n            ]\n            for layer, history in conflict_history_bn.items()\n        },\n        'training_metrics': {\n            'steps': [int(s) for s in training_metrics_bn['steps']],\n            'losses': [float(l) for l in training_metrics_bn['losses']],\n            'peak_conflict_layers': [int(l) for l in training_metrics_bn['peak_conflict_layers']]\n        },\n        'conflict_variance': {str(k): float(v) for k, v in conflict_variance_bn.items()}\n    },\n    \n    'stage_2_bn_ar': {\n        'metrics': {\n            'peak_migrations': int(migrations_ar),\n            'unique_peak_layers': list(unique_peaks_ar),\n            'initial_peak': int(peak_layers_ar[0]),\n            'final_peak': int(peak_layers_ar[-1]),\n            'layer_distance': int(layer_distance_ar),\n            'hypothesis_validated': bool(hypothesis_validated_ar)\n        },\n        'conflict_history': {\n            str(layer): [\n                {k: float(v) if isinstance(v, (int, float, np.number)) else int(v) \n                 for k, v in h.items()}\n                for h in history\n            ]\n            for layer, history in conflict_history_ar.items()\n        },\n        'training_metrics': {\n            'steps': [int(s) for s in training_metrics_ar['steps']],\n            'losses': [float(l) for l in training_metrics_ar['losses']],\n            'peak_conflict_layers': [int(l) for l in training_metrics_ar['peak_conflict_layers']]\n        },\n        'conflict_variance': {str(k): float(v) for k, v in conflict_variance_ar.items()}\n    },\n    \n    'overall_validation': {\n        'both_stages_validated': bool(hypothesis_validated_bn and hypothesis_validated_ar),\n        'at_least_one_validated': bool(hypothesis_validated_bn or hypothesis_validated_ar),\n        'en_bn_validated': bool(hypothesis_validated_bn),\n        'bn_ar_validated': bool(hypothesis_validated_ar)\n    }\n}\n\nwith open('cadea_sequential_transfer_data.json', 'w') as f:\n    json.dump(results, f, indent=2)\n\nprint(\"\\n✓ Results exported to: cadea_sequential_transfer_data.json\")\nprint(\"\\nℹ️  Data structure:\")\nprint(\"  ├─ stage_1_en_bn/\")\nprint(\"  │   ├─ metrics (summary statistics)\")\nprint(\"  │   ├─ conflict_history (per-layer gradients)\")\nprint(\"  │   ├─ training_metrics (loss, peak layers)\")\nprint(\"  │   └─ conflict_variance (non-stationarity measure)\")\nprint(\"  ├─ stage_2_bn_ar/ (same structure)\")\nprint(\"  └─ overall_validation (combined hypothesis results)\")\nprint(\"\\nℹ️  Next steps:\")\nprint(\"  1. Use for thesis Figure: conflict migration across stages\")\nprint(\"  2. Compare EN→BN vs BN→AR patterns for analysis section\")\nprint(\"  3. If validated → Implement CADEA with dynamic routing\")\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n# ============================================================================\n# FINAL FORGETTING ANALYSIS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"🔬 CATASTROPHIC FORGETTING ANALYSIS\")\nprint(\"=\"*80)\n\n# English forgetting\nen_initial_ppl = performance_tracking['after_en']['en']['perplexity']\nen_final_ppl = performance_tracking['after_ar']['en']['perplexity']\nen_total_degradation = ((en_final_ppl - en_initial_ppl) / en_initial_ppl) * 100\n\nprint(f\"\\n📉 ENGLISH FORGETTING:\")\nprint(f\"  Initial (after EN): {en_initial_ppl:.2f}\")\nprint(f\"  After BN: {performance_tracking['after_bn']['en']['perplexity']:.2f} ({en_degradation:+.1f}%)\")\nprint(f\"  After AR: {en_final_ppl:.2f} ({en_total_degradation:+.1f}%)\")\n\n# Bengali forgetting\nbn_initial_ppl = performance_tracking['after_bn']['bn']['perplexity']\nbn_final_ppl = performance_tracking['after_ar']['bn']['perplexity']\nbn_degradation = ((bn_final_ppl - bn_initial_ppl) / bn_initial_ppl) * 100\n\nprint(f\"\\n📉 BENGALI FORGETTING:\")\nprint(f\"  Initial (after BN): {bn_initial_ppl:.2f}\")\nprint(f\"  After AR: {bn_final_ppl:.2f} ({bn_degradation:+.1f}%)\")\n\n# Overall backward transfer\nprint(f\"\\n🎯 BACKWARD TRANSFER (BWT):\")\nprint(f\"  Average forgetting: {(en_total_degradation + bn_degradation) / 2:.1f}%\")\n\nif en_total_degradation > 10 or bn_degradation > 10:\n    print(f\"\\n✅ CATASTROPHIC FORGETTING CONFIRMED (>10% degradation)\")\n    print(f\"   → This validates the need for dynamic expert allocation\")\nelse:\n    print(f\"\\n⚠️  Mild forgetting observed (<10% degradation)\")\n    print(f\"   → Static model may be more robust than expected\")\n\n# Save results\nimport json\nwith open('performance_tracking.json', 'w') as f:\n    # Convert to serializable format\n    tracking_serializable = {}\n    for stage, langs in performance_tracking.items():\n        tracking_serializable[stage] = {\n            lang: {k: float(v) for k, v in metrics.items()}\n            for lang, metrics in langs.items()\n        }\n    json.dump(tracking_serializable, f, indent=2)\n\nprint(f\"\\n✓ Results saved to performance_tracking.json\")","metadata":{"_uuid":"2eca0396-1815-486a-9d21-8119ea365d79","_cell_guid":"ed7fc06e-941b-49d0-ac71-cf9a7dcd50fa","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}